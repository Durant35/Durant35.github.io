<!DOCTYPE html>
<html lang="zh-Hans">
<head>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="Gary" />



<meta name="description" content="Caltagirone L, Scheidegger S, Svensson L, et al. Fast lidar-based road detection using convolutional neural networks[J]. arXiv preprint arXiv:1703.03613, 2017.Demo Videos: https://www.youtube.com/wat">
<meta property="og:type" content="website">
<meta property="og:title" content="Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks">
<meta property="og:url" content="http://durant35.github.io/papers/01_Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks.html">
<meta property="og:site_name" content="Tarantula-7's Blog">
<meta property="og:description" content="Caltagirone L, Scheidegger S, Svensson L, et al. Fast lidar-based road detection using convolutional neural networks[J]. arXiv preprint arXiv:1703.03613, 2017.Demo Videos: https://www.youtube.com/wat">
<meta property="og:image" content="http://durant35.github.io/img/papers/01_ModelArchitecture.png">
<meta property="og:image" content="http://durant35.github.io/img/papers/01_ContextModule8Layers.png">
<meta property="og:image" content="http://durant35.github.io/img/papers/01_KITTIResults.png">
<meta property="og:updated_time" content="2017-06-16T12:27:23.521Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks">
<meta name="twitter:description" content="Caltagirone L, Scheidegger S, Svensson L, et al. Fast lidar-based road detection using convolutional neural networks[J]. arXiv preprint arXiv:1703.03613, 2017.Demo Videos: https://www.youtube.com/wat">
<meta name="twitter:image" content="http://durant35.github.io/img/papers/01_ModelArchitecture.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Tarantula-7&#39;s Blog" type="application/atom+xml">



    <link rel="shortcut icon" href="/img/favicon.ico">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks | Tarantula-7&#39;s Blog</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->






</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Gary</a></h1>
        </hgroup>

        
        <p class="header-subtitle">　　你永远流淌在我的记忆里？River flows in you</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">Home</a></li>
                        
                            <li><a href="/tags">All-tags</a></li>
                        
                            <li><a href="/archives">All-lists</a></li>
                        
                            <li><a href="/Shengjie">Contact</a></li>
                        
                            <li><a href="/about">About</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa 新浪微博" href="http://weibo.com/u/2911566017/home?topnav=1&wvr=6" title="新浪微博"></a>
                            
                                <a class="fa GitHub" href="https://github.com/Durant35" title="GitHub"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Android/">Android</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CMD/">CMD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CMake/">CMake</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CV/">CV</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DARPA/">DARPA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DLL/">DLL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JSP/">JSP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Key-words/">Key-words</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MFC/">MFC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NotePad/">NotePad++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OpenCL/">OpenCL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OpenGL/">OpenGL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PCB/">PCB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Qt/">Qt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROS/">ROS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/STM32/">STM32</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Socket/">Socket</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VS2013/">VS2013</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Windows/">Windows</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dumpbin/">dumpbin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ini/">ini</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pcap/">pcap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vim/">vim</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文件操作/">文件操作</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/漫威电影/">漫威电影</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编码/">编码</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://wiki.ros.org/">ROS</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://zhiqiu.github.io/">Zhiqiu&#39;s Blog</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://www.ruanyifeng.com/blog/">阮一峰的网络日志</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://rh-song.github.io/">RiHui-Song&#39;s Blog</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://goshin.github.io/">Goshin&#39;s Blog</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://blog.csdn.net/u014593748">Kangdk&#39;s CSDN</a>
                    
                    </div>
                </section>
                

                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Gary</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Gary</a></h1>
            </hgroup>
            
            <p class="header-subtitle">　　你永远流淌在我的记忆里？River flows in you</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">Home</a></li>
                
                    <li><a href="/tags">All-tags</a></li>
                
                    <li><a href="/archives">All-lists</a></li>
                
                    <li><a href="/Shengjie">Contact</a></li>
                
                    <li><a href="/about">About</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa 新浪微博" target="_blank" href="http://weibo.com/u/2911566017/home?topnav=1&wvr=6" title="新浪微博"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/Durant35" title="GitHub"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="page-undefined" class="article article-type-page" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/papers/01_Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks.html" class="article-date">
      <time datetime="2016-06-11T14:49:17.000Z" itemprop="datePublished">2016-06-11</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              <style>
    .article-meta { display: none; }
    #container .article .article-title { padding-right: 0; }
    .article-header {
        padding: 0;
        padding-top: 26px;
        border-left: none;
        text-align: center;
    }
    .article-header:hover { border-left: none; }
    .article-title { font-size: 1.6em }
    .article-entry hr { margin: 0;}
    .article-meta,
    #container .article-info-post.article-info { display: none;}
    #container .article .article-title { padding: 0; }
</style>

<!-- 匹配页面 -->

          
        <blockquote>
<p>Caltagirone L, Scheidegger S, Svensson L, et al. Fast lidar-based road detection using convolutional neural networks[J]. arXiv preprint arXiv:1703.03613, 2017.<br>Demo Videos: <a href="https://www.youtube.com/watch?v=bkwUyJxMUSM&amp;list=PLKaUu00MYU2hxVpERRJ2il5eCQ2MOO1LB">https://www.youtube.com/watch?v=bkwUyJxMUSM&amp;list=PLKaUu00MYU2hxVpERRJ2il5eCQ2MOO1LB</a></p>
</blockquote>
<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><ul>
<li>一句话概述本文内容：a <strong>deep learning approach</strong> has been developed to carry out <strong>road detection</strong> using only <strong>LiDAR</strong> data</li>
<li>主要工作<ul>
<li>unstructured point cloud（从激光雷达直接获得的点云数据）</li>
<li>generated <strong>top-view images</strong>(encoding several basic statistics such as <strong>mean height and density</strong>)：生成带高度均值、密度均值的俯视图 $\Longrightarrow$ <strong>road detection</strong> is reduced to <strong>a single-scale problem</strong>（单一尺度问题）</li>
<li>将生成的俯视图通过 a simple and fast convolutional neural network (CNN)<ul>
<li>怎样的一个 CNN？<ul>
<li>专用的，为 pixel-wise semantic segmentation（像素层面的语义分割） 而 specifically designed</li>
<li>方式：组合 a large receptive field（接受区/感受区 ） 和 high-resolution feature maps（高分辨率特征地图）<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/22627224">无痛理解CNN中的感受野receptive field</a>：在卷积神经网络CNN中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作<strong>感受野receptive field</strong></p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>成果说明<ul>
<li>KITTI road benchmark’s top-performing algorithm</li>
<li>outperforms the second best LIDAR-only approach by 7.4% points（检测更准确）</li>
<li>可用于实时需求高的应用：fast inference（快速检测）</li>
</ul>
</li>
</ul>
<h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><ul>
<li>road detection 很重要<ul>
<li><code>[1]</code>A. B. Hillel, R. Lerner, D. Levi, and G. Raz, “Recent progress in road and lane detection: a survey,” <em>Machine vision and applications</em>,<br>vol. 25, no. 3, pp. 727–745, 2014.：The estimation of <strong>free road surface</strong> (henceforth（后续使用 road detection 指代）: road detection) is a crucial component for enabling fully autonomous driving</li>
<li><strong>lane markings</strong> are not visible (covered by snow or due to poor lighting conditions) </li>
<li><strong>lane markings</strong> are not present (in certain rural and urban roads)</li>
<li>Besides <strong>obstacle avoidance</strong>, <strong>road detection</strong> can also facilitate（提升/促进） <strong>path planning</strong> and <strong>decision making</strong></li>
</ul>
</li>
<li>目前基于视觉的 road detection（<strong>camera-based approaches</strong>） 比较成熟，奈何摄像头易受环境光照影响 $\Longrightarrow$ 基于 LiDAR 的 road detection<ul>
<li>large variety of approaches can be found in the literature（阅读文献）<ul>
<li>large majority only work on <strong>monocular camera images</strong>（双目）</li>
<li>several make use of <strong>deep neural networks(DNNs)</strong>：<br>① automatically annotated images（自动标记图像）<br>② <code>[5]</code>L. Ankit, K. Mehmet, S. Luis, and M. Hebert, “Map-supervised road detection,” in <em>IEEE Intelligent Vehicles Symposium Proceedings</em>, 2016. fully convolutional neural network<br>③ <code>[4]</code>R. Mohan, “Deep deconvolutional networks for scene parsing,” <em>arXiv preprint arXiv:1411.4101</em>, 2014. trains <strong>deep deconvolutional networks</strong> using a <strong>multi-patch approach</strong> <blockquote>
<p><a href="https://www.zhihu.com/question/51914974">在看CNN的论文中，出现过大量的patch这个词，请问这个单词怎么理解？</a></p>
<ul>
<li>patch的基本意思是“一片大区域上的一小块区，特别是，这一小块和它周围是不一样的。”</li>
<li>来源于：医学中通过实时监测来观察神经细胞活跃程度的东东，目前有FMRI（功能性磁共振成像），它可以用来实时观察当人受到刺激或接受特定信息时，大脑哪些部分的脑细胞活跃，活跃的部分会显示出红色或者其他彩色（patches)，彩色面积越深、越大，表明越活跃</li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
<li>基于 LiDAR 的 road detection 方法太传统，还没有人将 deep 一些方法用在 road detection 的先例，所以效果也还没能达到基于视觉的水平 $\Longrightarrow$ 本论文的创新和贡献</li>
<li>本论文的工作概述<ul>
<li>road detection is framed as a <strong>pixel-wise semantic segmentation</strong> task in <strong>point cloud top-view images</strong> using a <strong>fully convolutional neural network (FCN)</strong></li>
<li>将road detection 问题框架化为以下的流程：使用 FCN 神经网络对点云俯视图进行像素层面的语义分割</li>
</ul>
</li>
<li><font color="red">如何将激光雷达点云数据转化成<strong>FCN 神经网络</strong>能够接受的<strong>点云俯视图</strong>呢？？？</font>

</li>
</ul>
<h4 id="Point-Cloud-Top-view-Road-Detection"><a href="#Point-Cloud-Top-view-Road-Detection" class="headerlink" title="Point Cloud Top-view Road Detection"></a>Point Cloud Top-view Road Detection</h4><ul>
<li>From point cloud to top-view images<ul>
<li>grid cell 投影法 $\Longrightarrow$ one grid cell, one pixel<ul>
<li>需要考虑好图像的 <em>x-y</em> 与激光雷达的放置方向（前方-右方）</li>
</ul>
</li>
<li>Some <strong>basic statistics</strong> are then computed for <strong>each grid cell</strong><ul>
<li>number of points（单网格点云数目）</li>
<li>mean reflectivity（强度均值）</li>
<li>mean height（高度均值）</li>
<li>standard deviation height（高度标准差）：$S = \sqrt{\frac{\sum_{i=1}^N (X_i - \overline{X})^2}{N}}$</li>
<li>minimum height（高度最小值）</li>
<li>maximum height（高度最大值）</li>
</ul>
</li>
</ul>
</li>
<li>Model architecture<ul>
<li>相关工作参考<ul>
<li>原始的 CNN 设计条件<ul>
<li>have a <strong>large receptive field</strong>（大感受野）</li>
<li>process <strong>high-resolution feature maps</strong>（高分辨率特征图）<blockquote>
<p><a href="https://www.zhihu.com/question/36514939">卷积神经网络（CNN）里的概念</a></p>
<ul>
<li>在每个卷积层，数据都是以三维形式存在的，可以把它看成许多个二维图片叠在一起，其中每一个称为一个<strong>feature map</strong><ul>
<li>在输入层，如果是灰度图片，那就只有一个feature map；如果是彩色图片，一般就是3个feature map（红绿蓝）</li>
</ul>
</li>
<li>层与层之间会有若干个卷积核（kernel），上一层和每个feature map跟每个卷积核做卷积，都会产生下一层的一个feature map</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li>模型架构来源（inspired）<ul>
<li>Segnet：<code>[14]</code>V. Badrinarayanan, A. Handa, and R. Cipolla, “Segnet: A deep convolutional encoder-decoder architecture for robust semantic pixel-wise labelling,” <em>arXiv preprint arXiv:1505.07293</em>, 2015.</li>
<li>FCN-8s：<code>[15]</code>J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation,” in <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2015, pp. 3431–3440.</li>
<li>Dilation：<code>[16]</code>F. Yu and V. Koltun, “Multi-scale context aggregation by dilated convolutions,” <em>arXiv preprint arXiv:1511.07122</em>, 2015.</li>
</ul>
</li>
<li>core idea（核心思路）<ul>
<li>①pretrained network（训练网络）＋ ②Additional specialized layers（专用层）</li>
<li>①：feature extractor, or encoder（特征提取器/编码器） $\Longrightarrow$ image classification（图片分类）</li>
<li>②：max unpooling and deconvolution（最大值去池化＋去卷积） $\Longrightarrow$ upsample the feature maps back to the original input size</li>
</ul>
</li>
</ul>
</li>
<li>Context module（卷积层模块）<ul>
<li>本论文提出的 FCNN Model architecture 中的 Context module<br><center><img src="/img/papers/01_ModelArchitecture.png" width="800px" alt=""/></center><ul>
<li>W：处理图片宽度</li>
<li>H：处理图片高度</li>
<li>D：处理特征图数目</li>
</ul>
</li>
<li>dilated convolution operator（扩展卷积算子）$\Longleftarrow$ expand the receptive field of a CNN while keeping the number of model parameters and layers small（大感受野+简单模型（参数、层数少））<ul>
<li>supports an <strong>exponential expansion of the receptive field</strong>（指数扩大感受野） without losing resolution (分辨率：特征图大小) or coverage（覆盖率）</li>
<li>限制模型卷积层层数：减少模型 memory requirements（内存需求），尤其要求 high-resolution feature maps（高分辨率特征图）</li>
</ul>
</li>
<li>8层扩展卷积层模块<br><center><img src="/img/papers/01_ContextModule8Layers.png" width="720px" alt=""/></center><ul>
<li>the <strong>receptive field</strong> of the <strong>last dilated convolution layer</strong> is larger than the input feature maps(100 x 200px)</li>
<li>access a large context window（更大的特征图窗口）$\Longrightarrow$ which is particularly important considering the sparsity of point cloud top-view images（适应点云的稀疏性特征）</li>
</ul>
</li>
</ul>
</li>
<li>本论文提出的 FCNN Model architecture（如上图）<ul>
<li>Six-channel input layer（6 通道输入，200×400）<ul>
<li>number of points（单网格点云数目图）</li>
<li>mean reflectivity（强度均值图）</li>
<li>mean height（高度均值图）<ul>
<li>pixel $\Longrightarrow$ grid cell</li>
<li>pixel value $\Longrightarrow$ mean height of the grid cell</li>
</ul>
</li>
<li>standard deviation height（高度标准差图）</li>
<li>minimum height（高度最小值图）</li>
<li>maximum height（高度最大值图）</li>
</ul>
</li>
<li>Encoder<ul>
<li>功能：<strong>subsample</strong>（子采样/下采样） the feature maps, thus reducing the model memory requirements</li>
<li>方法：<strong>max pooling</strong>（最大值池化，2×2 window and stride 2（跨步为2）） layer，即窗口大小2×2，窗口从初始位置以步长2为单位，向右、向下滑到末尾位置</li>
<li>具体操作：①Convolution 3x3, stride 1（3x3 窗口卷积，跨步1）, <strong>zero-padding</strong>（补零） + <strong>ELU</strong>（exponential linear unit 指数线性单元激活函数）；②再做一次①；③Max pooling 2x2, stride 2</li>
</ul>
</li>
<li>Context module<ul>
<li>目的： aggregates multi-scale contextual information（聚合尺度不同的上下文信息）</li>
<li>方法：<strong>dilated convolutions</strong>（扩大/扩展卷积算子<code>[16]</code>）</li>
<li>具体操作：①Dilated convolution（扩展卷积） 3x3, stride 1, zero-padding + spatial dropout（空间上Dropout来屏蔽部分神经元以防止过拟合） + ELU；②-⑦再做一次①；⑧Convolution 1x1</li>
</ul>
</li>
<li>Decoder<ul>
<li>目的：upsamples（上采样） the feature maps back to the input size</li>
<li>方法：<strong>max-unpooling</strong> layer（最大值去池化 <code>[14]</code>）followed by two convolutional layers</li>
<li>具体操作：①Max unpooling；②Convolution 3x3, stride 1（3x3 窗口卷积，跨步1）, <strong>zero-padding</strong>（补零） + <strong>ELU</strong>（exponential linear unit 指数线性单元激活函数）；③再做一次②；④Softmax（一个类似SVM的分类器）</li>
</ul>
</li>
<li>Output layer $\Longrightarrow$ a road confidence map<ul>
<li>road confidence map：an image where each pixel’s value represents the probability</li>
<li>pixel value 超过某个概率阈值 $\Longrightarrow$ corresponding grid cell 是否是可行驶道路网格？？</li>
</ul>
</li>
<li>设计策略<ul>
<li>Restricting the number of layers（限制网络的层数）<ul>
<li>主要目的：reduce the model memory requirements（especially when working with high-resolution feature maps）高分辨率特征地图</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Data-Set-and-Setup（数据集与训练）"><a href="#Data-Set-and-Setup（数据集与训练）" class="headerlink" title="Data Set and Setup（数据集与训练）"></a>Data Set and Setup（数据集与训练）</h4><ul>
<li>The KITTI data set<ul>
<li><strong>Ground truth annotations</strong> are represented in the camera perspective space</li>
<li>数据集集合<ul>
<li>training set（训练集）$\Longrightarrow$ 学习样本数据集，训练模型<ul>
<li>for computing the <strong>objective function</strong>（衰减函数）</li>
<li>for adjusting the CNN <strong>weights</strong>（权值）</li>
</ul>
</li>
<li>validation set（验证集） $\Longrightarrow$ 对学习出来的模型，调整分类器的参数；确定网络结构或者控制模型复杂程度的参数<ul>
<li>used to decide when to stop training</li>
<li>used for selecting the CNN <strong>hyperparameters</strong>（超参数） (number of layers, filters’size, and <strong>learning rate</strong>（学习率）) by choosing the model (from a largeset of runs) with the smallest <strong>validation error</strong>（验证误差）</li>
</ul>
</li>
<li>test set（测试集）$\Longrightarrow$ 测试已经训练好的模型的推广能力，检验最终选择最优的模型的性能如何<ul>
<li>for evaluating the model performance on unseen data (generalization error)：泛化误差<blockquote>
<p>当train出来一个model之后，parameters已经定了下来，然后用test dataset去test这个network，泛化误差就是test的时候的误差。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
<li><font color="red">如何对数据分成上述三类，然后被使用？</font></li>
</ul>
</li>
<li>Data augmentation（数据增广）<ul>
<li>目的：simple data augmentation was necessary in order to avoid <strong>overfitting</strong>（过拟合） and to improve model <strong>generalization</strong>（模型推广）</li>
<li>方法：rotate about the LIDAR z-axis for angles in the range $[-30°, 30°]$ using steps of three degrees（$\frac{60°}{3°} = 20$）</li>
</ul>
</li>
<li>Inverse perspective mapping（反向透视图） vs. point cloud projection（点云投影）：如何实现自动标定点云数据的呢？<ul>
<li>ground truth annotations are represented in the camera perspective：只在视觉图像中标定，因此能否将视觉图像中的标定信息转化到点云俯视图中，这样训练集就有我们需要的标定信息？</li>
<li>方法一：<strong>IPM(inverse perspective mapping)</strong> 反向透视图，不可行原因<ul>
<li>前提条件：<strong>flat and obstacle-free roads</strong>（平坦、无障碍的道路）$\Longrightarrow$ which are rarely satisfied in the real world</li>
<li>前提条件不满足造成的结果：produces images showing inaccurate distances and road geometries（点云俯视图距离与道路几何信息与实际产生偏差）</li>
</ul>
</li>
<li>方法二：project the point cloud into the corresponding <strong>camera-view annotation</strong>（标定好的图片） in order to determine which of its points belong to the road，即通过投影的方式，将点云投影到标定好的图片来根据投影到的图片像素标定类型自动标定点云数据（road/not-road）<ul>
<li><font color="red">具体怎么操作呢？？？</font></li>
<li>obtain a dense annotation（提高点云密度，得到密集的标定信息）$\Longrightarrow$ 对点云进行线性插值<ul>
<li>线性差值区间：within narrow circular sectors</li>
</ul>
</li>
<li>标记好点云后，还是通过投影到网格的方式生成带标定信息（road/not-road）的点云俯视图</li>
</ul>
</li>
</ul>
</li>
<li>Training（如何训练的呢？）<ul>
<li>Using the <strong>Adam optimization algorithm</strong>（Adam 优化算法 <code>[19]</code> D. Kingma and J. Ba, “Adam: A method for stochastic optimization,”<em>arXiv preprint arXiv:1412.6980</em>, 2014.）with an <strong>initial learning rate</strong> of 0.01</li>
<li>using <strong>cross-entropy loss</strong>（交叉熵损失）as the <strong>objective function</strong>：$L = - \frac{1}{N×W×H} \sum_{n=1}^N \sum_{w=1}^W \sum_{h=1}^H log \space p_{w, h}^n$<ul>
<li>N：the batch size which in this work was set to 4</li>
<li>W：the width of the softmax layer’s output</li>
<li>H：the height of the softmax layer’s output</li>
<li>p：the probability predicted by the CNN for the correct class</li>
</ul>
</li>
<li>The <strong>learning rate</strong> was decayed（学习率衰减） by a factor 2 whenever there was no improvement of performance within the last <strong>epoch</strong><blockquote>
<p><a href="https://www.zhihu.com/question/43673341">深度学习中 number of training epochs 中的 epoch到底指什么？</a></p>
<ul>
<li>一个<code>epoch</code>是指把所有训练数据完整的过一遍，即所有训练数据forward+backward后更新参数的过程</li>
<li><code>step num</code>：指的是训练的遍数</li>
<li><code>iteration</code>（迭代）：选取一个<code>batch</code>进行update，即<code>batch size</code>个训练数据forward+backward后更新参数过程，一个epoch的意思就是迭代次数×batch的数目，和训练数据的个数一样，就是一个epoch</li>
<li><code>batch size</code>：指的是每一次迭代的训练，使用数据的个数</li>
</ul>
</blockquote>
</li>
<li>For <strong>regularization</strong>（正则化）, <strong>spatial dropout layers</strong>（防止过拟合 <code>[20]</code> J. Tompson, R. Goroshin, A. Jain, Y. LeCun, and C. Bregler, “Efficient object localization using convolutional networks,” in <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2015, pp. 648–656.） ($p_d = 0.25$) were added after each <strong>dilated convolution layer</strong></li>
</ul>
</li>
</ul>
<h4 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h4><ul>
<li>KITTI road benchmark 实验结果分析<ul>
<li>几个指标<ul>
<li>precision (PRE)</li>
<li>recall (REC)</li>
<li>false positive rate (FPR)</li>
<li>false negative rate (FNR)</li>
<li>average precision (AP)</li>
<li>maximum F1-measure (MaxF)：$MaxF = max_τ 2 × \frac{PRE(τ ) × REC(τ )}{PRE(τ ) + REC(τ )}$，$τ$ 是 classification threshold（分类阈值）</li>
</ul>
</li>
<li>KITTI 对比结果<br><center><img src="/img/papers/01_KITTIResults.png" width="540px" alt=""/></center><ul>
<li>achieved state-of-the-art（最先进的） performance</li>
<li>inference time is significantly smaller（适合实时性要求高的实际应用）</li>
<li>the boundary between regions that have a high probability of being part of the road and those that do not is very sharpre，sulting road region almost uniformly blue（检测结果区分明显）</li>
</ul>
</li>
<li>可能问题：false positive detections（假阳性检测，即错检）<ul>
<li>原因<ul>
<li>boundary between road and sidewalk was not sharp（道路与人行道边界不明显：高度差很小，小到微不足道）</li>
<li>complex road scenes, such as intersections（路口等复杂路况）</li>
</ul>
</li>
<li>解决方法<ul>
<li>extending the training set</li>
<li>considering additional features for generating top-view images</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Regions of interest study（performance 受距离的影响：点云越远越稀疏）<ul>
<li>LIDAR-acquired point clouds are <strong>sparse</strong> and have <strong>densities that decrease</strong> with distance from the sensor</li>
<li>considering smaller ROIs with higher density of points：随距离变远，performance degrades steadily（均匀下降）</li>
<li>可能的解决方法：accumulate points over successive scans（利用连续几帧点云数据累积）</li>
</ul>
</li>
<li>Point-cloud vs. IPM annotations（两种标定方法对比）<ul>
<li>using <strong>IPM</strong> often do not match properly with their corresponding <strong>PCP(point cloud projecting)</strong>‘s point cloud top-view images</li>
<li>our model performance increases significantly in all the considered metrics（使用PCP所有评估指标都有所提升）</li>
</ul>
</li>
<li>Occupancy images（点云 $\Longrightarrow$ 占用图：white pixel if there is at least one detection, black otherwise）<ul>
<li>使用的点云俯视图只考虑单一网格（individual grid cells）中的信息，如何才能得到更高的准确率呢？<ul>
<li>将临近网格的信息也考虑进来</li>
<li>考虑网格内的点云空间分布情况</li>
<li>另外：选择哪些统计信息？这些统计信息如何组合使用？</li>
</ul>
</li>
<li>使用一种 Occupancy images 训练 CNN<ul>
<li>interesting preliminary result（初步结果表明）：CNN 能够得到 high performance</li>
<li>说明什么情况：top-view perspective, already contains strong discriminative information for road detection（点云俯视图中点云的2D分布已经有明显的道路检测区分信息）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Conclusion-and-Future-Work"><a href="#Conclusion-and-Future-Work" class="headerlink" title="Conclusion and Future Work"></a>Conclusion and Future Work</h4><ul>
<li>Conclusion<ul>
<li>KITTI road benchmark(only LiDAR data) $\Longrightarrow$ point  cloud top-view images $\Longrightarrow$ CNN $\Longrightarrow$ road detection</li>
<li>优势或成果<ul>
<li>基于 LiDAR：in any lighting conditions</li>
<li>GPU 加速：works in real time on GPU-accelerated hardware $\Longrightarrow$ 可用于 integrated into high-level driving automation systems</li>
</ul>
</li>
</ul>
</li>
<li>Future Work（没提及任何可扩展，不过在实验部分有列出一些可考虑的方向）<ul>
<li>false positive detections（错检问题）<ul>
<li>原因<ul>
<li>boundary between road and sidewalk was not sharp（道路与人行道边界不明显：高度差很小，小到微不足道）</li>
<li>complex road scenes, such as intersections（路口等复杂路况）</li>
</ul>
</li>
<li>解决方法<ul>
<li>extending the training set</li>
<li>considering additional features for generating top-view images</li>
</ul>
</li>
</ul>
</li>
<li>performance 受距离的影响：点云越远越稀疏<ul>
<li>accumulate points over successive scans（利用连续几帧点云数据累积）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="参考阅读"><a href="#参考阅读" class="headerlink" title="参考阅读"></a>参考阅读</h4><ul>
<li><a href="http://www.cnblogs.com/bzjia-blog/tag/Deep%20Learning/">博客园：Deep Learning</a></li>
<li><a href="http://blog.csdn.net/v_july_v/article/details/51812459">CNN笔记：通俗理解卷积神经网络</a></li>
<li><a href="http://blog.csdn.net/qq_20259459/article/details/70316511">深度学习 14. 深度学习调参，CNN参数调参，各个参数理解和说明以及调整的要领。underfitting和overfitting的理解，过拟合的解释</a></li>
</ul>

      
    </div>
    
  </div>
  
    


  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Point-Cloud-Top-view-Road-Detection"><span class="toc-number">3.</span> <span class="toc-text">Point Cloud Top-view Road Detection</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Data-Set-and-Setup（数据集与训练）"><span class="toc-number">4.</span> <span class="toc-text">Data Set and Setup（数据集与训练）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Experiments"><span class="toc-number">5.</span> <span class="toc-text">Experiments</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Conclusion-and-Future-Work"><span class="toc-number">6.</span> <span class="toc-text">Conclusion and Future Work</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#参考阅读"><span class="toc-number">7.</span> <span class="toc-text">参考阅读</span></a></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-4 i,
        .toc-level-4 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"true"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
        <!--
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
        -->
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
        <!--
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
        -->
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks　| Tarantula-7's Blog　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    
        <section id="comments">
    <style> aside.comment-bar { margin: auto 30px; }</style>
    <div id="disqus_thread"></div>
    <script>
        var disqus_config = function(){
            this.page.url = 'http://durant35.github.io/papers/01_Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks.html';
            this.page.identifier = 'papers/01_Fast LIDAR-based Road Detection Using Fully Convolutional Neural Networks.html';
        };
        var loadComment = function(){
            var d = document, s = d.createElement('script');
            s.src = '//durant35.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        }
    </script>
    
    <script> loadComment(); </script>

</section>


    





    <script>
        
    </script>



</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2014-2017 Gary
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by <a href="http://moxfive.xyz/" target="_blank"> MOxFIVE </a><i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
             post: ".article-entry a[href], .copyright a[href]", 
            
            
            
            
            
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>